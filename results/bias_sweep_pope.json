{
  "model": "llava-hf/llava-1.5-7b-hf",
  "benchmark": "pope",
  "target_layers": [8, 9, 10, 11, 12, 13, 14, 15, 16],
  "num_samples": 200,
  "sweep": {
    "0.0":  {"accuracy": 0.8200, "correct": 164, "total": 200},
    "0.5":  {"accuracy": 0.8200, "correct": 164, "total": 200},
    "1.0":  {"accuracy": 0.8150, "correct": 163, "total": 200},
    "2.0":  {"accuracy": 0.8450, "correct": 169, "total": 200},
    "3.0":  {"accuracy": 0.8300, "correct": 166, "total": 200},
    "5.0":  {"accuracy": 0.5150, "correct": 103, "total": 200},
    "8.0":  {"accuracy": 0.5000, "correct": 100, "total": 200},
    "10.0": {"accuracy": 0.5000, "correct": 100, "total": 200}
  },
  "analysis": {
    "optimal_bias": 2.0,
    "optimal_accuracy": 0.8450,
    "baseline_accuracy": 0.8200,
    "improvement": 0.025,
    "note": "Clear inverted-U pattern: bias 2.0 is optimal (+2.5% over baseline). Bias >= 5.0 catastrophically collapses to chance (50%), likely because the model attends almost exclusively to visual tokens and ignores the question text. Bias 3.0 still helps (+1.0%) but less than 2.0."
  }
}
