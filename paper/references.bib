@inproceedings{liu2024visual,
  title={Visual Instruction Tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  booktitle={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{liu2024improved,
  title={Improved Baselines with Visual Instruction Tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}

@inproceedings{leng2024mitigating,
  title={Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding},
  author={Leng, Sicong and Zhang, Hang and Chen, Guanzheng and Li, Xin and Lu, Shijian and Miao, Chunyan and Bing, Lidong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13763--13773},
  year={2024}
}

@inproceedings{li2023evaluating,
  title={Evaluating Object Hallucination in Large Vision-Language Models},
  author={Li, Yifan and Du, Yifan and Zhou, Kun and Wang, Jinpeng and Zhao, Wayne Xin and Wen, Ji-Rong},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={292--305},
  year={2023}
}

@inproceedings{chen2024are,
  title={Are We on the Right Way for Evaluating Large Vision-Language Models?},
  author={Chen, Lin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and Zang, Yuhang and Chen, Zehui and Duan, Haodong and Wang, Jiaqi and Qiao, Yu and Lin, Dahua and Zhu, Feng},
  booktitle={Advances in Neural Information Processing Systems},
  volume={37},
  year={2024}
}

@inproceedings{hudson2019gqa,
  title={{GQA}: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering},
  author={Hudson, Drew A. and Manning, Christopher D.},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6700--6709},
  year={2019}
}

@inproceedings{clark2019what,
  title={What Does {BERT} Look At? {A}n Analysis of {BERT}'s Attention},
  author={Clark, Kevin and Khandelwal, Urvashi and Levy, Omer and Manning, Christopher D.},
  booktitle={Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  pages={276--286},
  year={2019}
}

@inproceedings{voita2019analyzing,
  title={Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned},
  author={Voita, Elena and Talbot, David and Moiseev, Fedor and Sennrich, Rico and Titov, Ivan},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={5797--5808},
  year={2019}
}

@inproceedings{vaswani2017attention,
  title={Attention is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{radford2021learning,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle={Proceedings of the 38th International Conference on Machine Learning},
  pages={8748--8763},
  year={2021}
}

@article{alayrac2022flamingo,
  title={Flamingo: A Visual Language Model for Few-Shot Learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and Ring, Roman and Rutherford, Eliza and Cabi, Serkan and Han, Tengda and Gong, Zhitao and Samangooei, Sina and Monteiro, Mariangela and Menick, Jacob and Borgeaud, Sebastian and Brock, Andrew and Nematzadeh, Aida and Sharifzadeh, Sahand and Bi\'nkowski, Miko{\l}aj and Barreira, Ricardo and Vinyals, Oriol and Zisserman, Andrew and Simonyan, Karen},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{li2023blip2,
  title={{BLIP-2}: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  pages={19730--19742},
  year={2023}
}

@inproceedings{zhu2024minigpt,
  title={{MiniGPT-4}: Enhancing Vision-Language Understanding with Advanced Large Language Models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@inproceedings{yin2024woodpecker,
  title={Woodpecker: Hallucination Correction for Multimodal Large Language Models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Xu, Tong and Wang, Hao and Sui, Dianbo and Shen, Yunhang and Li, Ke and Sun, Xing and Chen, Enhong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2024}
}

@inproceedings{zhou2024analyzing,
  title={Analyzing and Mitigating Object Hallucination in Large Vision-Language Models},
  author={Zhou, Yiyang and Cui, Chenhang and Yoon, Jaehong and Zhang, Linjun and Deng, Zhun and Finn, Chelsea and Bansal, Mohit and Yao, Huaxiu},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@inproceedings{darcet2024vision,
  title={Vision Transformers Need Registers},
  author={Darcet, Timoth\'{e}e and Oquab, Maxime and Mairal, Julien and Jegou, Herv\'{e}},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@article{touvron2023llama,
  title={{LLaMA}: Open and Efficient Foundation Language Models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth\'{e}e and Rozi\`{e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@inproceedings{vig2019multiscale,
  title={A Multiscale Visualization of Attention in the Transformer Model},
  author={Vig, Jesse},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
  pages={37--42},
  year={2019}
}

@inproceedings{abnar2020quantifying,
  title={Quantifying Attention Flow in Transformers},
  author={Abnar, Samira and Zuidema, Willem},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4190--4197},
  year={2020}
}

@article{dosovitskiy2021image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weisenbuch, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{huang2024opera,
  title={{OPERA}: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation},
  author={Huang, Qidong and Dong, Xiaoyi and Zhang, Pan and Wang, Bin and He, Conghui and Wang, Jiaqi and Lin, Dahua and Zhang, Weiming and Yu, Nenghai},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13418--13427},
  year={2024}
}

@inproceedings{guan2024hallusionbench,
  title={{HallusionBench}: An Advanced Diagnostic Suite for Entangled Language Hallucination and Visual Illusion in Large Vision-Language Models},
  author={Guan, Tianrui and Liu, Fuxiao and Wu, Xiyang and Xian, Ruiqi and Li, Zongxia and Liu, Xiaoyu and Wang, Xijun and Chen, Lichang and Huang, Furong and Yacoob, Yaser and Manocha, Dinesh and Zhou, Tianyi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14194--14204},
  year={2024}
}

@article{wang2024mllmguard,
  title={Mitigating Hallucination in Visual Language Models with Visual Supervision},
  author={Wang, Zhixin and Yu, Tianlong and Wu, Yifan and Wang, Bolin},
  journal={arXiv preprint arXiv:2311.16479},
  year={2023}
}

@article{favero2024multi,
  title={Multi-Modal Hallucination Control by Visual Information Grounding},
  author={Favero, Alessandro and Wen, Luca and Huttenlocher, Daniel and Koltun, Vladlen},
  journal={arXiv preprint arXiv:2403.14003},
  year={2024}
}

@inproceedings{yue2024less,
  title={Less is More: Mitigating Multimodal Hallucination from an {EOS} Decision Perspective},
  author={Yue, Zihao and Zhang, Liang and Jin, Qin},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics},
  pages={5765--5780},
  year={2024}
}

@inproceedings{jiang2024hallucination,
  title={Hallucination Augmented Contrastive Learning for Multimodal Large Language Model},
  author={Jiang, Chaoya and Xu, Haiyang and Ye, Mengfan and Ye, Qinghao and Yan, Ming and Ji, Haixin and Zhang, Ji and Huang, Fei and Huang, Shao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={27036--27046},
  year={2024}
}

@inproceedings{bai2024hallucination,
  title={Hallucination of Multimodal Large Language Models: A Survey},
  author={Bai, Zechen and Wang, Pichao and Xiao, Tianjun and He, Tong and Han, Zongbo and Zhang, Zheng and Shou, Mike Zheng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2025}
}

@article{olsson2022context,
  title={In-context Learning and Induction Heads},
  author={Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Johnston, Scott and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
  journal={Transformer Circuits Thread},
  year={2022}
}

@article{elhage2021mathematical,
  title={A Mathematical Framework for Transformer Circuits},
  author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
  journal={Transformer Circuits Thread},
  year={2021}
}

@inproceedings{meng2022locating,
  title={Locating and Editing Factual Associations in {GPT}},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17359--17372},
  year={2022}
}

@inproceedings{geva2023dissecting,
  title={Dissecting Recall of Factual Associations in Auto-Regressive Language Models},
  author={Geva, Mor and Bastings, Jasmijn and Filippova, Katja and Globerson, Amir},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={12216--12235},
  year={2023}
}

@inproceedings{chen2024image,
  title={An Image is Worth More Than 16x16 Patches: Exploring Transformers on Individual Pixels},
  author={Chen, Duy-Kien and Houlsby, Neil and Zhai, Xiaohua},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@inproceedings{tong2024eyes,
  title={Eyes Wide Shut? {E}xploring the Visual Shortcomings of Multimodal {LLMs}},
  author={Tong, Shengbang and Liu, Zhuang and Zhai, Yuexiang and Ma, Yi and LeCun, Yann and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9568--9578},
  year={2024}
}

@article{guo2017calibration,
  title={On Calibration of Modern Neural Networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
  booktitle={Proceedings of the 34th International Conference on Machine Learning},
  pages={1321--1330},
  year={2017}
}

@inproceedings{bavishi2019understanding,
  title={Understanding Attention for Text Classification},
  author={Bao, Yu and Chang, Shiyu and Yu, Mo and Barzilay, Regina},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={2418--2428},
  year={2019}
}

@inproceedings{jain2019attention,
  title={Attention is not Explanation},
  author={Jain, Sarthak and Wallace, Byron C.},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={3543--3556},
  year={2019}
}

@inproceedings{wiegreffe2019attention,
  title={Attention is not not Explanation},
  author={Wiegreffe, Sarah and Pinter, Yuval},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},
  pages={11--20},
  year={2019}
}

@article{zhai2023halle,
  title={{HaELM}: Hallucination Evaluation for Large Language Models},
  author={Zhai, Yuchen and Tong, Shengbang and Li, Xiao and Cai, Mu and Qu, Qing and Lee, Yong Jae and Ma, Yi},
  journal={arXiv preprint arXiv:2305.11747},
  year={2023}
}

@article{wu2024jailbreaking,
  title={Jailbreaking {GPT-4V} via Self-Adversarial Attacks with System Prompts},
  author={Wu, Yuanwei and Xie, Xiang and Zhu, Yixin and Xie, Cihang},
  journal={arXiv preprint arXiv:2311.09127},
  year={2023}
}
